{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2966b9",
   "metadata": {},
   "source": [
    "1) /Users/arka_bagchi/Desktop/AirDNA/Raw_data/airdna_raw_rental_properties_202309101133_a.csv\n",
    "2) /Users/arka_bagchi/Desktop/AirDNA/Raw_data/airdna_raw_rental_property_file_202309101155_a.tsv\n",
    "3) /Users/arka_bagchi/Desktop/AirDNA/Raw_data/us_Monthly_Match_2022-07-06.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9890cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/7gn92qw92_z23w6s9k9sxtfm0000gq/T/ipykernel_29274/1307913696.py:4: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  us_monthly_match_df = pd.read_csv('/Users/arka_bagchi/Desktop/AirDNA/Sampled_data/us_Monthly_Match_sampled.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV and TSV files into pandas DataFrames\n",
    "us_monthly_match_df = pd.read_csv('/Users/arka_bagchi/Desktop/AirDNA/Sampled_data/us_Monthly_Match_sampled.csv')\n",
    "airdna_df = pd.read_csv('/Users/arka_bagchi/Desktop/AirDNA/Sampled_data/airdna_sampled.csv')\n",
    "airdna_rental_property_df = pd.read_csv('/Users/arka_bagchi/Desktop/AirDNA/Sampled_data/airdna_rental_property_sampled.tsv', delimiter='\\t')\n",
    "\n",
    "# Now you have three DataFrames: us_monthly_match_df, airdna_df, and airdna_rental_property_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff1055e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Property ID', 'Property Type', 'Listing Type', 'Bedrooms', 'Reporting Month', 'Occupancy Rate', 'Revenue (USD)', 'Revenue (Native)', 'ADR (USD)', 'ADR (Native)', 'Number of Reservations', 'Reservation Days', 'Available Days', 'Blocked Days', 'Country', 'State', 'City', 'Zipcode', 'Neighborhood', 'Metropolitan Statistical Area', 'Latitude', 'Longitude', 'Active', 'Scraped During Month', 'Currency Native', 'Airbnb Property ID', 'Airbnb Host ID', 'HomeAway Property ID', 'HomeAway Property Manager']\n"
     ]
    }
   ],
   "source": [
    "us_monthly_match_columns = us_monthly_match_df.columns.tolist()\n",
    "print(us_monthly_match_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0cda37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Property_ID', 'Property_Type', 'Listing_Type', 'Bedrooms', 'Reporting_Month', 'Occupancy_Rate', 'Currency', 'Revenue', 'Revenue_Potential', 'ADR', 'Number_of_Reservations', 'Reservation_Days', 'Available_Days', 'Blocked_Days', 'Country', 'State', 'City', 'Zipcode', 'Neighborhood', 'Metropolitan_Statistical_Area', 'Latitude', 'Longitude', 'Active', 'Scraped_During_Month', 'Airbnb_Property_ID', 'Airbnb_Host_ID', 'Vrbo_Property_ID', 'Vrbo_Host_ID', 'Property_Manager', 'validated_zipcode']\n"
     ]
    }
   ],
   "source": [
    "airdna_columns = airdna_df.columns.tolist()\n",
    "print(airdna_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0727ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VRBO Host ID', 'Security Deposit', 'Longitude', 'Listing Title', 'Has Parking', 'Cancellation Policy', 'Airbnb Communication Rating', 'Revenue Potential LTM', 'Property Type', 'Listing Images', 'Last Calendar Update', 'Has Hot Tub', 'Country', 'City', 'Bedrooms', 'Airbnb Accuracy Rating', 'Published Weekly Rate', 'Neighborhood', 'Airbnb Location Rating', 'AirDNA Market', 'ADR', 'VRBO Property ID', 'Response Rate', 'Published Monthly Rate', 'Pets Allowed', 'Occupancy Rate LTM', 'Max Guests', 'Listing Type', 'Host Type', 'Has Pool', 'Created Date', 'Bathrooms', 'Property ID', 'Overall Rating', 'Minimum Stay', 'Location Type', 'License', 'Exact Location', 'Cleaning Fee', 'Price Tier', 'Listing URL', 'Has Kitchen', 'Currency', 'Count Reservation Days LTM', 'Airbnb Checkin Rating', 'Response Time', 'Property Manager', 'Number of Reviews', 'Number of Photos', 'Number of Bookings LTM', 'Latitude', 'Extra People Fee', 'Count Blocked Days LTM', 'Count Available Days LTM', 'Zipcode', 'State', 'Amenities', 'AirDNA Submarket', 'Revenue LTM', 'Has Air Con', 'Airbnb Value Rating', 'Published Nightly Rate', 'Listing Main Image URL', 'Last Scraped Date', 'Metropolitan Statistical Area', 'Has Gym', 'Airbnb Superhost', 'Real Estate Property Type', 'Instantbook', 'Airbnb Property ID', 'Airbnb HOST ID', 'Airbnb Cleanliness Rating']\n"
     ]
    }
   ],
   "source": [
    "airdna_rental_property_columns = airdna_rental_property_df.columns.tolist()\n",
    "print(airdna_rental_property_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c84c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/29 15:08:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/29 15:08:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"AirDNA Analysis\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8aa066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/29 15:10:57 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: zip:/Users/arka_bagchi/Desktop/AirDNA/Raw_data/airdna_raw_rental_properties_202309101133_a.csv.zip.\n",
      "org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"zip\"\n",
      "\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n",
      "\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n",
      "\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n",
      "\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o27.csv.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"zip\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/arka_bagchi/Desktop/AirDNA/Raw_data/airdna_raw_rental_properties_202309101133_a.csv.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m zip_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o27.csv.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"zip\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "zip_path = \"/Users/arka_bagchi/Desktop/AirDNA/Raw_data/airdna_raw_rental_properties_202309101133_a.csv.zip\"\n",
    "zip_df = spark.read.option(\"header\", \"true\").csv(f\"zip:{zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e655ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gzip_tsv_path = \"/Users/arka_bagchi/Desktop/AirDNA/Raw_data/airdna_raw_rental_property_file_202309101155_a.tsv.gz\"\n",
    "gzip_tsv_df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \"\\t\").csv(gzip_tsv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa2683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip_csv_path = \"/Users/arka_bagchi/Desktop/AirDNA/Raw_data/us_Monthly_Match_2022-07-06.csv.gz\"\n",
    "gzip_csv_df = spark.read.option(\"header\", \"true\").csv(gzip_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6496adba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/29 15:13:15 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------------+--------------------+-----------+-------------------+---------------------------+---------------------+-------------------+--------------------+--------------------+-----------+-------------+-------------+--------+----------------------+---------------------+------------+----------------------+-----------------+------+----------------+-------------+----------------------+------------+------------------+----------+---------------+---------+--------+------------+---------+-------------+--------------+------------+--------------------+-------+--------------+------------+----------+--------------------+-----------+--------+--------------------------+---------------------+-------------+----------------+-----------------+----------------+----------------------+-------------+----------------+----------------------+------------------------+-------+----------+--------------------+----------------+-----------+-----------+-------------------+----------------------+----------------------+-------------------+-----------------------------+-------+----------------+-------------------------+-----------+------------------+--------------+-------------------------+\n",
      "|VRBO Host ID|Security Deposit|      Longitude|       Listing Title|Has Parking|Cancellation Policy|Airbnb Communication Rating|Revenue Potential LTM|      Property Type|      Listing Images|Last Calendar Update|Has Hot Tub|      Country|         City|Bedrooms|Airbnb Accuracy Rating|Published Weekly Rate|Neighborhood|Airbnb Location Rating|    AirDNA Market|   ADR|VRBO Property ID|Response Rate|Published Monthly Rate|Pets Allowed|Occupancy Rate LTM|Max Guests|   Listing Type|Host Type|Has Pool|Created Date|Bathrooms|  Property ID|Overall Rating|Minimum Stay|       Location Type|License|Exact Location|Cleaning Fee|Price Tier|         Listing URL|Has Kitchen|Currency|Count Reservation Days LTM|Airbnb Checkin Rating|Response Time|Property Manager|Number of Reviews|Number of Photos|Number of Bookings LTM|     Latitude|Extra People Fee|Count Blocked Days LTM|Count Available Days LTM|Zipcode|     State|           Amenities|AirDNA Submarket|Revenue LTM|Has Air Con|Airbnb Value Rating|Published Nightly Rate|Listing Main Image URL|  Last Scraped Date|Metropolitan Statistical Area|Has Gym|Airbnb Superhost|Real Estate Property Type|Instantbook|Airbnb Property ID|Airbnb HOST ID|Airbnb Cleanliness Rating|\n",
      "+------------+----------------+---------------+--------------------+-----------+-------------------+---------------------------+---------------------+-------------------+--------------------+--------------------+-----------+-------------+-------------+--------+----------------------+---------------------+------------+----------------------+-----------------+------+----------------+-------------+----------------------+------------+------------------+----------+---------------+---------+--------+------------+---------+-------------+--------------+------------+--------------------+-------+--------------+------------+----------+--------------------+-----------+--------+--------------------------+---------------------+-------------+----------------+-----------------+----------------+----------------------+-------------+----------------+----------------------+------------------------+-------+----------+--------------------+----------------+-----------+-----------+-------------------+----------------------+----------------------+-------------------+-----------------------------+-------+----------------+-------------------------+-----------+------------------+--------------+-------------------------+\n",
      "|        NULL|            1000|      -80.21537|5 Bdrm House Clos...|       true|             strict|                         10|              32340.0|              House|\"[\"\"https://a0.mu...| 2023-07-30 21:53:44|      false|United States|        Miami|       5|                    10|                 2093|   Coral Way|                    10|        MIAMI, FL|536.79|       7863000ha|          100|                  8372|       false|          0.273885|        10|Entire home/apt|2-5 Units|   false|  2015-12-14|      2.0|abnb_10000216|          NULL|           4|  Large City - Urban|   NULL|          NULL|         249|   economy|https://www.airbn...|       true|     usd|                        43|                   10|        117.5|            NULL|               86|              20|                     7|      25.7651|               0|                    46|                     114|  33135|   Florida|\"[\"\"free_parking\"...|            NULL|    23082.0|       true|                  9|                   425|  https://a0.muscac...|2023-07-30 14:53:44|         Miami-Fort Lauder...|  false|           false|              House/villa|      false|          10000216|      49633363|                        9|\n",
      "|        NULL|             200|     -122.34761|Queen Anne Doll H...|      false|           flexible|                          9|                 NULL|          Apartment|\"[\"\"https://a0.mu...| 2021-01-09 22:25:20|      false|United States|      Seattle|       2|                    10|                 1750|  Queen Anne|                    10|      SEATTLE, WA|  NULL|            NULL|          100|                  7000|       false|              NULL|         5|Entire home/apt|2-5 Units|   false|  2015-12-14|      2.0|abnb_10000273|          97.0|         180|  Large City - Urban|   NULL|          NULL|          75|   economy|https://www.airbn...|       true|     usd|                      NULL|                   10|       1054.5|            NULL|                8|              23|                  NULL|     47.62556|               0|                  NULL|                    NULL|  98109|Washington|\"[\"\"elevator\"\",\"\"...|            NULL|       NULL|      false|                  9|                   125|  https://a0.muscac...|2021-01-09 22:25:20|         Seattle-Tacoma-Be...|  false|            NULL|           Apt/Condo/Loft|       true|          10000273|      51372899|                       10|\n",
      "|        NULL|             100|      -122.4409|Cozy Private Room...|      false|             strict|                         10|              23409.0|Condominium (condo)|\"[\"\"https://a0.mu...| 2023-07-30 08:10:23|      false|United States|San Francisco|       1|                    10|                  525|  The Castro|                    10|SAN FRANCISCO, CA|150.38|            NULL|          100|                  2100|        true|          0.521739|         1|   Private room|2-5 Units|   false|  2015-12-14|      1.0|abnb_10000523|          97.0|          30|  Large City - Urban|   NULL|          NULL|         200|  midscale|https://www.airbn...|       true|     usd|                        24|                   10|      14141.0|            NULL|               19|              40|                     7|     37.75709|              25|                   255|                      22|  94114|California|\"[\"\"kitchen\"\",\"\"w...|            NULL|     3609.0|      false|                  9|                   115|  https://a0.muscac...|2023-08-03 08:05:46|         San Francisco-Oak...|  false|           false|           Apt/Condo/Loft|      false|          10000523|      42786654|                       10|\n",
      "|        NULL|            NULL|-121.9054145417|Zigzag Mt. Hideaw...|       true|           flexible|                         10|                 NULL|              House|\"[\"\"https://a0.mu...| 2018-11-24 13:37:15|      false|United States| Rhododendron|       1|                    10|                  175|        NULL|                    10|      OREGON AREA|  NULL|            NULL|          100|                   700|       false|              NULL|         1|    Shared room|21+ Units|   false|  2015-12-14|      1.0|abnb_10000550|          96.0|           1|Destination/Resor...|   NULL|          NULL|        NULL|    budget|https://www.airbn...|       true|     usd|                      NULL|                   10|        404.0|            NULL|               31|               9|                  NULL|45.3249452151|               0|                  NULL|                    NULL|  97049|    Oregon|\"[\"\"fireplace\"\",\"...|            NULL|       NULL|      false|                 10|                    25|  https://a0.muscac...|2018-11-24 13:37:15|         Portland-Vancouve...|  false|            NULL|              House/villa|      false|          10000550|      41114629|                       10|\n",
      "|        NULL|            NULL| -84.3839370059|Walk Midtown | He...|       true|               NULL|                         10|                 NULL|Condominium (condo)|\"[\"\"https://a0.mu...| 2018-07-10 05:16:08|      false|United States|      Atlanta|       1|                     8|                 2100|     Midtown|                    10|      ATLANTA, GA|  NULL|            NULL|           80|                  8400|        true|              NULL|         2|   Private room|21+ Units|   false|  2015-12-14|      1.5|abnb_10000707|          87.0|           1|  Large City - Urban|   NULL|          NULL|         100|    luxury|https://www.airbn...|       true|     usd|                      NULL|                   10|       4778.0|         StayATL|               21|              10|                  NULL| 33.778656074|              50|                  NULL|                    NULL|  30309|   Georgia|\"[\"\"kitchen\"\",\"\"f...|            NULL|       NULL|       true|                  9|                   400|  https://a0.muscac...|2018-07-10 05:16:08|         Atlanta-Sandy Spr...|  false|            NULL|           Apt/Condo/Loft|      false|          10000707|       4610788|                        8|\n",
      "+------------+----------------+---------------+--------------------+-----------+-------------------+---------------------------+---------------------+-------------------+--------------------+--------------------+-----------+-------------+-------------+--------+----------------------+---------------------+------------+----------------------+-----------------+------+----------------+-------------+----------------------+------------+------------------+----------+---------------+---------+--------+------------+---------+-------------+--------------+------------+--------------------+-------+--------------+------------+----------+--------------------+-----------+--------+--------------------------+---------------------+-------------+----------------+-----------------+----------------+----------------------+-------------+----------------+----------------------+------------------------+-------+----------+--------------------+----------------+-----------+-----------+-------------------+----------------------+----------------------+-------------------+-----------------------------+-------+----------------+-------------------------+-----------+------------------+--------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+--------+---------------+--------------+-------------+----------------+---------+------------+----------------------+----------------+--------------+------------+-------------+-------+-----------+-------+------------+-----------------------------+-----------------+------------------+------+--------------------+---------------+------------------+--------------+--------------------+-------------------------+\n",
      "|Property ID|Property Type|Listing Type|Bedrooms|Reporting Month|Occupancy Rate|Revenue (USD)|Revenue (Native)|ADR (USD)|ADR (Native)|Number of Reservations|Reservation Days|Available Days|Blocked Days|      Country|  State|       City|Zipcode|Neighborhood|Metropolitan Statistical Area|         Latitude|         Longitude|Active|Scraped During Month|Currency Native|Airbnb Property ID|Airbnb Host ID|HomeAway Property ID|HomeAway Property Manager|\n",
      "+-----------+-------------+------------+--------+---------------+--------------+-------------+----------------+---------+------------+----------------------+----------------+--------------+------------+-------------+-------+-----------+-------+------------+-----------------------------+-----------------+------------------+------+--------------------+---------------+------------------+--------------+--------------------+-------------------------+\n",
      "| ab-1936902|        House|Private room|       1|     2016-09-01|          NULL|         NULL|            NULL|     NULL|        NULL|                     0|               0|             0|          30|United States|Florida|Miami Beach|  33141|        NULL|         Miami-Fort Lauder...|25.85845681423581|-80.13004301372736| False|                True|            USD|           1936902|       3322060|                NULL|                     NULL|\n",
      "| ab-1936902|        House|Private room|       1|     2016-10-01|           0.0|         NULL|            NULL|     NULL|        NULL|                     0|               0|            29|           2|United States|Florida|Miami Beach|  33141|        NULL|         Miami-Fort Lauder...|25.85845681423581|-80.13004301372736|  True|                True|            USD|           1936902|       3322060|                NULL|                     NULL|\n",
      "| ab-1936902|        House|Private room|       1|     2016-11-01|          NULL|         NULL|            NULL|     NULL|        NULL|                     0|               0|             0|          30|United States|Florida|Miami Beach|  33141|        NULL|         Miami-Fort Lauder...|25.85845681423581|-80.13004301372736| False|                True|            USD|           1936902|       3322060|                NULL|                     NULL|\n",
      "| ab-1936902|        House|Private room|       1|     2016-12-01|          NULL|         NULL|            NULL|     NULL|        NULL|                     0|               0|             0|          31|United States|Florida|Miami Beach|  33141|        NULL|         Miami-Fort Lauder...|25.85845681423581|-80.13004301372736| False|                True|            USD|           1936902|       3322060|                NULL|                     NULL|\n",
      "| ab-1936902|        House|Private room|       1|     2017-01-01|          NULL|         NULL|            NULL|     NULL|        NULL|                     0|               0|             0|          31|United States|Florida|Miami Beach|  33141|        NULL|         Miami-Fort Lauder...|25.85845681423581|-80.13004301372736| False|               False|            USD|           1936902|       3322060|                NULL|                     NULL|\n",
      "+-----------+-------------+------------+--------+---------------+--------------+-------------+----------------+---------+------------+----------------------+----------------+--------------+------------+-------------+-------+-----------+-------+------------+-----------------------------+-----------------+------------------+------+--------------------+---------------+------------------+--------------+--------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For the TSV DataFrame:\n",
    "gzip_tsv_df.show(n=5)\n",
    "\n",
    "# For the CSV DataFrame:\n",
    "gzip_csv_df.show(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
